{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebf3eff6-d45b-4717-abf2-28797f0e98bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TechXchange Barcelona\n",
    "\n",
    "## Lab 2084 - Deploying Large Language Models (LLMs) on OpenShift for IBM Power\n",
    "\n",
    "Author: Marvin Gie√üing (marving@de.ibm.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961c6272-201c-4b09-ae3e-ebfcfca1ec38",
   "metadata": {},
   "source": [
    "## Respond to natural language questions using RAG approach\n",
    "\n",
    "This notebook contains the steps and code to demonstrate support of Retrieval Augumented Generation using a local model deployed on Power10. It introduces commands for data retrieval, knowledge base building & querying, and model testing.\n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python 3.10.\n",
    "\n",
    "#### About Retrieval Augmented Generation\n",
    "Retrieval Augmented Generation (RAG) is a versatile pattern that can unlock a number of use cases requiring factual recall of information, such as querying a knowledge base in natural language.\n",
    "\n",
    "In its simplest form, RAG requires 3 steps:\n",
    "\n",
    "- Phase 1: Index knowledge base passages (once)\n",
    "- Phase 2: Retrieve relevant passage(s) from knowledge base (for every user query)\n",
    "- Phase 3: Generate a response by feeding retrieved passage into a large language model (for every user query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6e875b-ea62-4795-950d-ec52250570fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"setup\"></a>\n",
    "## Setup environment and import relevant libraries\n",
    "\n",
    "As one of the main components will be a document file (we use a PDF) the main imports are pypdf to parse that and pymilvus to set up the knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d962a7-befd-4dfb-953d-c360b5121caf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MILVUS_HOST=\"milvus-service\"\n",
    "MILVUS_PORT=\"19530\"\n",
    "\n",
    "LLAMA_HOST=\"llama-service\"\n",
    "LLAMA_PORT=\"8080\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8f29a7-b98c-4a5a-801f-32447d7e3379",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Clean up before starting :)\n",
    "\n",
    "from pymilvus import connections, utility\n",
    "\n",
    "# Connect to Milvus Database\n",
    "connections.connect(host=\"milvus-service\", port=\"19530\")\n",
    "\n",
    "colls = utility.list_collections()\n",
    "print(colls)\n",
    "\n",
    "for coll in colls:\n",
    "    utility.drop_collection(coll)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01b3131-dfa2-477a-86a2-79cee9ce403b",
   "metadata": {},
   "source": [
    "## Phase 1: Ingesting data & build up knowledge base\n",
    "![image](https://github.com/mgiessing/watsonx-rag/blob/main/images/Ingest_Data.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba66299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the sample PDF file\n",
    "import requests\n",
    "import os\n",
    "FNAME = \"HarryPotter.pdf\"\n",
    "\n",
    "if not os.path.exists(FNAME):\n",
    "    res = requests.get('https://ibm.box.com/shared/static/d5rfawbu2tvny6zkh1o96u8797qimwmv.pdf')\n",
    "    with open(FNAME, 'wb') as file:\n",
    "        file.write(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0153c250-5d57-45c7-b34c-f43108cd2bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Milvus\n",
    "from langchain.document_loaders import WebBaseLoader, PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "#loader = WebBaseLoader([\n",
    "    #\"https://www.redbooks.ibm.com/redpapers/pdfs/redp5612.pdf\",\n",
    "#])\n",
    "\n",
    "loader = PyPDFLoader(\"HarryPotter.pdf\")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=768, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(docs)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ea9c60-5f85-4864-a47a-d819aab599bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756a6662-cbae-4de4-bc94-76c09542d705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "vector_store = Milvus.from_documents(\n",
    "    docs,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"demo\",\n",
    "    connection_args={\"host\": MILVUS_HOST, \"port\": MILVUS_PORT}\n",
    ")\n",
    "\n",
    "utility.list_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775f950f-8ed7-4afa-a090-bc3c8f428dd6",
   "metadata": {},
   "source": [
    "## Phase 2: Retrieve relevant passage(s) from Knowledge Base\n",
    "![image](https://github.com/mgiessing/watsonx-rag/blob/main/images/Retrieve_Data.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac48c54-4f7d-417f-bc8b-6c49577bee3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "questions = [\"What was the job of Mr. Dursley?\", \"What does Mr. Dursley look like?\", \"Where does the Dursley family live?\"]\n",
    "question = questions[0] # \"What was the job of Mr. Dursley?\"\n",
    "\n",
    "docs = vector_store.similarity_search_with_score(question, k=3)\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434f4b3e-2664-41a0-9209-8dafd58eefd5",
   "metadata": {},
   "source": [
    "## Phase 3: Build prompt, pass to LLM & generate Response\n",
    "![image](https://github.com/mgiessing/watsonx-rag/blob/main/images/Generate_Response.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80046bb7-56b3-4c3d-a0d4-131c3e4fede7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_prompt(question, topn_chunks: list[str]):\n",
    "    prompt = \"Instructions: Compose a single, short sentence that only answers the query, using the provided search results.\"\\\n",
    "             \"If the search results do not mention anything say 'Found nothing.'\\n\\n\"\n",
    "  \n",
    "    prompt += \"Search results:\\n\"\n",
    "    for chunk in topn_chunks:\n",
    "        prompt += f\"[Page {chunk[0].metadata['page']}]: \" + chunk[0].page_content.replace(\"\\n\", \" \") + \"\\n\\n\"\n",
    "\n",
    "    prompt += f\"Query: {question}\\n\\nAnswer: \"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e3420c-71ac-4b51-b8be-e05701dd2cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = build_prompt(question, docs)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33389b9-8eda-4958-a9c0-015d20e2da18",
   "metadata": {},
   "source": [
    "### 3a) Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d542ef27-9c70-41df-aecc-3802910ee65c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "json_data = {\n",
    "    'prompt': prompt,\n",
    "    'temperature': 0.1,\n",
    "    'n_predict': 100,\n",
    "    'stream': False,\n",
    "}\n",
    "\n",
    "res = requests.post(f'http://{LLAMA_HOST}:{LLAMA_PORT}/completion', json=json_data)\n",
    "\n",
    "res.json()['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcefdbbb-793f-410f-9d56-c4a55077bd65",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3b) Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2a5e53-4502-4200-86b6-7f961e8fdff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import httpx\n",
    "import json\n",
    "\n",
    "json_data = {\n",
    "    'prompt': prompt,\n",
    "    'temperature': 0.1,\n",
    "    'n_predict': 100,\n",
    "    'stream': True,\n",
    "}\n",
    "\n",
    "client = httpx.AsyncClient(timeout=30) #set higher timeout, because long prompt evaluation might take longer\n",
    "lastChunks = \"\"\n",
    "async with client.stream('POST', f'http://{LLAMA_HOST}:{LLAMA_PORT}/completion', json=json_data) as response:\n",
    "    async for chunk in response.aiter_bytes():\n",
    "        try:\n",
    "            data = json.loads(chunk.decode('utf-8')[6:])\n",
    "        except:\n",
    "            pass\n",
    "        if data['stop'] is False:\n",
    "            print(data['content'], end=\"\")\n",
    "        else:\n",
    "            print('\\n\\n')\n",
    "            print(data['timings'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b42aa11",
   "metadata": {},
   "source": [
    "## (Optional) exercises if you finish early :)\n",
    "\n",
    "In order to get better results you have a few options to try out:\n",
    "- Experiment with the parameters (e.g. temperature, top-k, top-p, n_predict )\n",
    "- Experiment with the prompt/instruction\n",
    "- Try out a different model (make sure to use a pre-converted `.gguf` model)\n",
    "- Load your own PDF if you like something more domain/business specific than Harry Potter :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60158791",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
